
\chapter{Logiche temporali e model-checking}
\label{Capitolo 6}
Per capire l'importanza di questo argomento pensiamo di avere un codice
concorrente scritto in un certo linguaggio, con l'utilizzo dei \textit{thread},
con un produttore, un consumatore e un buffer. I primi due estendono la classe
\textit{thread} mentre il buffer ha i metodi \textit{synchronized} per il
prelevamento e il deposito. Questo codice simula il modello
produttore-consumatore già approfondito. Bisogna capire se questo programma
funzioni correttamente ma non posso usare le tecniche viste precedentemente per
valutare la correttezza di programmi (logica di Hoare etc$\ldots$) in quanto
abbiamo a che fare con un programma che non inizia, produce dati e finisce ma,
generalmente, si ha a che fare con un programma senza stato finale, che esegue
infinitamente le sue parti in modo concorrente. Per il modello appena ipotizzato
possiamo dire che è corretto se, ad esempio:
\begin{itemize}
  \item ogni oggetto prodotto venga prima o poi consumato
  \item nessun oggetto venga consumato più di una volta
  \item il sistema non vada in deadlock
\end{itemize}
Pensiamo ora ad una rete di Petri ``complessa'' con due processi che
condividono in un mutua esclusione una certa risorsa. Si ha quindi una sezione
critica dove un processo usa tale risorsa. Possiamo volere, per esempio, che i
due processi non siano mai contemporaneamente nella sezione critica (userebbero
insieme la risorsa) e che prima o poi un processo entri in zona critica. Un
metodo è controllare l'intero spazio delle marcature raggiungibili e verificare
che tutto vada come voluto, per la prima richiesta, ma ci sono tecniche
migliori.  
\begin{nota}
    Volendo si può adattare la logica di Hoare a modelli concorrenti ma solo se si
ha comunque un output finale e non un'evoluzione ciclica infinita.
\end{nota}
\section{Logica PLTL/LTL}
Fino'ora ci si è basati sulla logica proposizionale ma tale logica ha dei
limiti, si introduce quindi la 
\textbf{logica PLTL (\textit{Propositional Linear Time Logic})} che introduce il
concetto di \textbf{tempo}, in ottica \textbf{lineare}, nel processo
logico. La logica temporale lineare o LTL (dall'inglese Linear Temporal Logic) è un'estensione della logica modale nella quale i mondi sono organizzati in una struttura lineare infinita: ogni mondo può così rappresentare un istante di tempo discreto. La logica LTL prevede dunque una organizzazione del tempo lineare, discreta, orientata al futuro e infinita. 
\begin{nota}
    Tale logica è anche abbreviata in \textbf{LTL (\textit{Linear Time
    Logic})}.
\end{nota}
La logica PLTL viene usata per \textbf{model checking} e lo scopo generale che
ci si propone è quello di presentare un approccio formale alla progettazione e
all'implementazione di sistemi basato su un linguaggio formale che permetta di
specificarli e ragionare sulle loro proprietà. Si vogliono studiare sia sistemi
grandi, come software o addirittura sistemi operativi, che piccoli, come per
esempio una coppia di semafori. Tutti questi sistemi hanno però la medesima
caratteristica, ovvero assumono in ogni \textbf{istante di tempo} un determinato
\textbf{stato} definito dalle \textbf{variabili} del sistema stesso. Si hanno
quindi nel sistema, in ogni istante di tempo:
\begin{itemize}
  \item uno \textbf{stato}, univocamente definito dai valori delle variabili
  \item una \textbf{transizione} che segnala un passaggio da uno stato ad un
  altro
  \item una \textbf{computazione} che rappresenta una sequenza di stati di cui
  ogni coppia forma una transizione. Si introduce quindi il concetto
  \textbf{temporale} 
\end{itemize}
Il \textbf{tempo} viene pensato come un oggetto discreto, scandito dalle
transizioni, su cui può essere definita anche una relazione d'ordine (potrebbe
servire che un processo termini prima, dopo o nello stesso tempo di un altro).
\subsection{Sistemi Reattivi e Correttezza degli stessi}
\begin{definizione}[Sistema Reattivo]
  Si definisce \textbf{sistema reattivo} come una componente:
  \begin{itemize}
    \item non terminante e interattiva
    \item che può leggere il proprio input non solo all'inizio della
    computazione e che può produrre output non solo alla fine della sua
    computazione (si possono quindi avere multipli input e multipli output)
    \item che interagisce con altri componenti distribuiti o concorrenti
  \end{itemize}
  Sono quindi:
  \begin{itemize}
    \item sistemi concorrenti, distribuiti e asincroni
    \item Non obbediscono al paradigma input-computazione-output
    \item non si possono analizzare con gli strumenti della logica di Hoare
  \end{itemize}
  avendo come esempi di comportamento:
  \begin{itemize}
    \item ``se un messaggio è stato spedito, prima o poi sarà consegnato al
    destinatario''
    \item ``La spia d’allarme resta accesa fino a quando il dispositivo viene
    spento'' 
    \item ``a partire da qualsiasi stato è possibile riportare il sistema allo
    stato iniziale''
  \end{itemize}
\end{definizione} \vspace{5mm} %5mm vertical space
Bisogna stabilire la correttezza di un sistema reattivo esprimendo il criterio
di correttezza come formula di un opportuno linguaggio logico. Il sistema
reattivo si modella tramite un sistema di transizioni, chiamati \textbf{modelli
di Kripke}, e valutando se la formula è vera nel sistema di transizioni, tramite
logiche temporali e algoritmi specifici.\\
Si hanno sistemi non terminanti che usano un numero \textbf{finito} di
variabili e di conseguenza si ha un numero di stati, in cui transita il sistema,
\textbf{finito}. Si hanno infatti sistemi di transizione finiti che
\textit{``comprimono''} sistemi non terminanti, con computazioni di lunghezza
infinita, in una rappresentazione finita.
Si ricorda che si possono inoltre categorizzare le proprietà che vogliamo
specificare come: 
\begin{itemize}
  \item \textbf{proprietà di safety}
  \item \textbf{proprietà di liveness}
  \item \textbf{proprietà di fairness}
\end{itemize}
\subsection{Modelli di Kripke}
Introduciamo quindi meglio i \textbf{modelli di Kripke}.\\
\begin{definizione}
  Definiamo un \textbf{sistema di transizioni} $A$ come:
  \[A=(Q, T)\]
  con:
  \begin{itemize}
    \item $Q$ come insieme di stati (potrebbe essere infinito ma studieremo i
    casi finiti)
    \item $T\subseteq Q\times Q$ insieme delle transizioni di stato che portano
    da uno stato ad un altro
  \end{itemize}
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{definizione}
  Definiamo \textbf{cammino} come:
  \[\pi=q_0q_1q_2\ldots,\,\,\, q_i\in T,\,\,\, \forall\, i\]
  \begin{corollario}
  
  Un cammino può essere infinito.
  \end{corollario}
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{definizione}
  
  Definiamo \textbf{cammino massimale} un cammino che non può più essere esteso. Spesso si tratta di \textbf{cammini infiniti}.
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{definizione}
  Definiamo un \textbf{modello di Kripke} $A$ come un sistema di transazioni a
  cui ad ogni stato è associato, dato l'insieme delle proposizioni atomiche
  $AP=\{z_1, z_2,\ldots z_n\}$, un insieme  di
  proposizioni atomiche che sono vere in quello stato:
  \[A=(Q, T, I)\]
  avendo una \textbf{funzione di interpretazione} $I$, che mi restituisce
  l'insieme delle proposizioni atomiche vere in uno stato, tale che:
  \[I:Q\to 2^{AP}\]
  \begin{nota}
  $2^{AP}$ è l'insieme delle parti di $AP$.
  \end{nota}
 \begin{nota}
  Potrei avere stati dove nessuna proposizione atomica è vera avendo il
  sottoinsieme associato vuoto.
 \end{nota}
\begin{nota}
   Non si specifica di base uno stato iniziale ma si può arricchire la
  definizione con uno stato iniziale.
\end{nota}
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{esempio}
  Vediamo un esempio:
  \begin{figure}[H]
    \centering
    \begin{tikzpicture}[node distance=2.5cm, bend angle=45, auto]
      \node [place] (p0) [label=below left:\small q] {\small 1};
      \node [place] (p1) [right of = p0, label=below left:\small q] {\small 2};
      \node [place] (p2) [right of = p1, label=below left:\small p] {\small 5};
      \node [place] (p3) [below of = p0, label=below left:{\small p, r}] {\small 4}; 
      \node [place] (p4) [below of = p1, label=below left:{\small p, q}] {\small 3}; 
      \node [place] (p5) [below of = p2, label=below left:{\small p, r}] {\small 6}; 
      \path[-{Latex[width=2mm]}]
      (p0) edge (p1)
      (p1) edge (p2)
      (p1) edge (p4)
      (p4) edge (p3)
      (p3) edge (p0)
      (p2) edge [bend left= 25](p5)
      (p5) edge [bend left= 25](p2)
      ;
    \end{tikzpicture}
  \end{figure}
  Dove:
  \begin{itemize}
    \item $AP=\{p, q, r\}$, insieme delle proposizioni atomiche
    \item $Q=\{1, 2, 3, 4, 5, 6\}$, insieme degli stati (fingiamo che $1$ sia lo
    stato iniziale)
    \item $T=\{(1, 2),(2, 3),(2, 5),(5, 6),(6, 5),\cdots\}$, insieme delle
    transizioni 
    \item $I(4) =\{p, r\}$, $I(2) =\{q\}$ etc$\ldots$, gli altri sono indicati
    in basso a sinistra di ogni stato
    \item $1, 2, 5$ è un cammino non massimale
    \item $1, 2, 5, 6,\overline{5, 6}$ è un cammino massimale (qui indico con la
    linea sopra gli stati in cui poi si continua a ciclare)
    \item $1, 2, 3, 4,\overline{1, 2, 3, 4}$ è un cammino massimale
    \item $1, 2, 3, 4, 1, 2, 5, 6,\overline{5, 6}$ è un cammino massimale
  \end{itemize}
\end{esempio}
\begin{definizione}
  Definiamo le famiglie di cammini massimali, indicandole in una notazione tipo
  regex, ($\,^*$ per indicare una o più ripetizione e $\,^\omega$ per indicare
  un ciclo infinito), come le ``tipologie'' di cammino che si possono avere.
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{esempio}
  Nell'esempio sopra si hanno le seguenti famiglie di cammini massimali:
  \begin{itemize}
    \item $(1234)^\omega$
    \item $(1234)^{*}(12)(56)^\omega$
  \end{itemize}
\end{esempio}
Si può quindi già intuire che:
\begin{definizione}
   Le logiche temporali sono frammenti della logica del primo ordine
\end{definizione}
Infatti con le logiche temporali, come la \textit{logica PLTL}, si supera il
limite di rappresentazione temporale della logica proposizionale\footnote{From Wikipedia: La logica proposizionale (o enunciativa) è un linguaggio formale con una semplice struttura sintattica, basata fondamentalmente su proposizioni elementari (atomi) e su connettivi logici di tipo vero-funzionale, che restituiscono il valore di verità di una proposizione in base al valore di verità delle proposizioni connesse (solitamente noti come AND, OR, NOT...). La semantica della logica proposizionale definisce il significato dei simboli e di qualsiasi proposizione che rispetti le regole sintattiche del linguaggio, basandosi sui valori di verità associati agli atomi. Data una interpretazione (o modello) di una proposizione (in generale di un insieme di proposizioni), e cioè una associazione tra le proposizioni elementari e le realtà rappresentate, possiamo generare un insieme infinito di proposizioni con significato definito che riguardino quella realtà. Ciascuna proposizione si riferisce quindi a uno o più oggetti della realtà rappresentata (anche astratta, ovviamente) e permette di descrivere o ragionare su quell'oggetto, utilizzando i due soli valori "Vero" e "Falso".}, permettendo,
per esempio, di rappresentare proposizioni del tipo \textit{``prima o poi'',
  ``accade sempre che'' etc$\ldots$}.\\
Si ha un \textbf{tempo lineare e discreto}, che si può pensare di rappresentare
nella logica classica proposizionale (per esempio come indice) ma questo
comporta il doversi dotare di infinite variabili proposizionali (corrispondenti
ad ogni \textit{``step''} temporale) e comporta l'ottenimento di una formula
proposizionale di lunghezza infinita. Si può pensare di passare allo studio di
questi casi con la \textit{logica predicativa}\footnote{From Wikipedia: Nella logica matematica il linguaggio del primo ordine è un linguaggio formale che serve per gestire meccanicamente enunciati e ragionamenti che coinvolgono i connettivi logici, le relazioni e i quantificatori "per ogni ..." (∀) ed "esiste..." (∃). L'espressione "del primo ordine" indica che c'è un insieme di riferimento e i quantificatori possano riguardare solo gli elementi di tale insieme e non i sottoinsiemi; ad esempio si può dire "per tutti gli x elementi dell'insieme vale P(x)" ma non si può dire "per tutti i sottoinsiemi A vale P(A)" (le teorie in cui ci sono quantificatori che spaziano sui sottoinsiemi dell'insieme di riferimento sono dette invece del secondo ordine). } ma sarebbe ben più del
necessario, in quanto le procedure sarebbero di complessità molto elevata, a
causa della grande espressività della logica predicativa. Inoltre la logica dei
predicati è indecidibile. \\
Si cerca quindi la via di mezzo cercando logiche specializzate, meno espressive
della logica predicativa ma decidibili rispetto ai problemi presi in
considerazione. Si cerca una logica con procedure efficienti rispetto
all'ampiezza della descrizione del problema in analisi (ovvero tipicamente
l'ampiezza del sistema di transizioni), che è direttamente proporzionale al
numero di stati del sistema (lineare rispetto al numero degli stati), e rispetto
alla lunghezza della formula che esprime la proprietà da testare.

\subsection{Sintassi}
Vediamo innanzitutto la \textbf{sintassi} della logica PLTL che chiamiamo anche
LTL.\\
Si ha a che fare con un \textit{vocabolario} più ampio rispetto a quelli della
logica proposizionale, vengono infatti aggiunti dei \textbf{connettivi} utili
alla rappresentazione temporale richiesta.
\begin{definizione}
  Nella logica PLTL, oltre ai connettivi logici classici della logica
  proporzionale, si definiscono i seguenti connettivi:
  \begin{itemize}
    \item \textbf{X}, detto anche \textbf{next} o \textbf{tomorrow}. È un
    connettivo unario e viene rappresentato con $\circ$. Esprime l'idea: \textit{"Nel prossimo stato della computazione"}
    \item \textbf{F}, detto anche \textbf{sometime} o \textbf{future}. È un
    connettivo unario e viene rappresentato con $\diamond$. Esprime l'idea: \textit{"Da un certo punto in poi ..."}
    \item \textbf{G}, detto anche \textbf{globally} o \textbf{always}. È un
    connettivo unario e viene rappresentato con $\square$. Esprime l'idea: \textit{"E' sempre vero che..."}
    \item \textbf{U}, detto anche \textbf{until}. È un connettivo binario. Esprime l'idea: \textit{"Se vale una formula allora varrà anche un'altra..."}
  \end{itemize}
  \subsubsection{Approfondimento}
  Viene inoltre indicato con $V$ l'\textbf{insieme delle variabili
    proposizionali}, l'\textbf{insieme delle proposizioni atomiche},
  variabili che hanno lo stesso significato della logica
  proposizionale, quindi ogni variabile corrisponde ad una singola proposizione
  del linguaggio naturale. 
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{nota}
    indichiamo con $V$ quello che prima chiamavamo $AP$.
\end{nota}
\begin{definizione}
  Diamo ora una definizione, formale, procedendo per induzione di
  \textbf{formula ben formata} del linguaggio PLTL (definendo così l'aspetto
  sintattico della logica PLTL): 
  \begin{itemize}
    \item $\forall p\in V$ vale che $p$ è una formula del linguaggio PLTL,
    ovvero le variabili proposizionali della logica classica sono formule del
    linguaggio PLTL. Questa è una \emph{formula atomica}
    \item i simboli $\top$ (detto anche \emph{true} che semanticamente
    semplifica
    una tautologia) e $\bot$ (detto anche \textit{false} o \emph{bottom} che
    semanticamente specifica una formula sempre falsa, ovvero una
    contraddizione) sono formule del linguaggio PLTL. Anche questa è una
    \emph{formula atomica}
    \item se $A$ è una formula del linguaggio PLTL allora lo sono anche:
    \begin{itemize}[label=$\ast$]
      \item $\neg A$
      \item $\mathbf{X}A$
      \item $\mathbf{F}A$
      \item $\mathbf{G}A$
    \end{itemize}
   
    \item  se $A$ e $B$ sono formule del linguaggio PLTL allora lo sono anche:
    \begin{itemize}[label=$\ast$]
      \item $A\to B$
      \item $A\land B$
      \item $A\lor B$
      \item $A\mathbf{U}B$ (anche $\mathbf{U}(A, B)$)
    \end{itemize}
    \item nient'altro appartiene all'insieme delle formule del linguaggio PLTL
  \end{itemize}
  Quindi si nota come \textbf{l'insieme delle formule PLTL contiene quello delle
    formule classiche della logica proporzionale}. Si ha quindi che l'insieme
  delle formule PLTL non è altro che un'estensione di quello delle formule
  classiche della logica proposizionale.
\end{definizione} \vspace{5mm} %5mm vertical space
Si hanno varianti della logica temporale con anche operatori relativi al passato
ma non sono utili in merito al model checking.
\begin{definizione}
  La sintassi delle formule del linguaggio PLTL possono essere definite usando
  anche la notazione \textbf{BNF (Backus-Naur Form o Backus Normal Form)},
  ovvero, $\forall p\in V$:
  \[A::=p\,|\,\top\,|\,\bot\,|\,(\neg A)\,|\,(A\land A)\,|\,(A\lor A)\,|\,(A\to
    A)\,|\,(\mathbf{X}A)\,|\,(\mathbf{F}A)\,|\,(\mathbf{G}A)\,|\,(A\mathbf{U}A)
  \] 
  Non si è usata quindi una definizione ricorsiva ma viene invece usata una
  \textbf{grammatica}\\
  \begin{shaded}
    La BNF (Backus-Naur Form o Backus Normal Form) è una metasintassi, ovvero un
    formalismo attraverso cui è possibile descrivere la sintassi di linguaggi
    formali (il prefisso meta ha proprio a che vedere con la natura circolare di
    questa definizione). Si tratta di uno strumento molto usato per descrivere
    in modo preciso e non ambiguo la sintassi dei linguaggi di programmazione,
    dei protocolli di rete e così via, benché non manchino in letteratura esempi
    di sue applicazioni a contesti anche non informatici e addirittura non
    tecnologici. La BNF viene usata nella maggior parte dei testi sulla teoria
    dei linguaggi di programmazione e in molti testi introduttivi su specifici
    linguaggi. \\
    In termini formali, la BNF può essere vista come un formalismo per descrivere
    grammatiche libere dal contesto.  \\
    Una specifica BNF è un insieme di regole di derivazione ciascuna espressa
    nella forma: 
    \begin{center}
      \textit{<simbolo> ::= \_espressione\_}
    \end{center}
  \end{shaded}
\end{definizione} \vspace{5mm} %5mm vertical space
Il cammino nel modello di Kripke corrisponde ad una esecuzione di un sistema,
che è una sequenza di stati. 
\subsection{Semantica}
\begin{definizione}
  La \textbf{semantica}, ovvero il significato dei connettivi della logica PLTL,
  è data usando i cosiddetti \textbf{modelli lineari} (si ricorda l'uso di un
  tempo lineare).\\
  Si consideri una struttura algebrica di questo tipo:
  \[M=\langle S,\,\rho, \,\to, \,\Vdash\rangle\]
  dove:
  \begin{itemize}
    \item $S$ è un \textbf{insieme infinito di stati}, detti anche
    \textbf{mondi}
    \item $\rho \in S$ è uno stato del modello detto anche \textbf{root} o
    \textbf{radice}. In tale stato viene codificato il \textbf{tempo zero}
    \item $\to$ è una relazione binaria su $S$ detta \textbf{relazione di
      transizione} la quale introduce un \textbf{ordinamento lineare} sugli
    elementi di $S$. Si ha quindi che:
    \[\to\,\subseteq S\times S\]
    e, $\forall \alpha \in S$, \textbf{esiste ed è unico} $\beta\in S$ tale che
    vale:
    \[\alpha\to\beta\]
    Preso quindi uno stato qualsiasi abbiamo un solo modo per passare ad un altro
    stato (esiste quindi un ``prima'' e un ``dopo'').\\
    Inoltre vale che, $\forall \alpha\in S$, $\alpha\not\to \rho$, dove $\rho\in
    S$ è l'unico elemento di $S$ a godere di questa proprietà (in quanto $\rho$
    codifica il tempo zero). 
    \item $\Vdash$ è una relazione binaria, inclusa in $S\times V$, detta
    \textbf{relazione di soddisfacibilità}. Solitamente con $\alpha\Vdash p$
    si indica che $(\alpha, p)\in\,\Vdash$ è valido, ovvero che $\alpha$
    \textbf{soddisfa} $p$, con $\alpha\in S$ e $p\in V$
  \end{itemize}
    \begin{definizione}
      
  La struttura $M$ viene detta \textbf{modello per PLTL}.
  \end{definizione} \vspace{5mm} %5mm vertical space
  \begin{nota}
      
  Si noti come questi modelli lineari seguano un ordinamento simile a quello che
  si ha tra i numeri in $\mathbb{N}$.
  \end{nota}
  \begin{nota}
      
  Si noti come la semantica della logica PLTL sia drasticamente più complessa
  di quella della logica classica proposizionale
  \end{nota}
\end{definizione} \vspace{5mm} %5mm vertical space

Bisogna dare ora significato ai connettivi PLTL. Per i connettivi della logica
proposizionale si usano tavole di verità e induzione ma per la logica PLTL le
cose sono un po' diverse.\\
Per dare un significato alle formule del linguaggio PLTL bisogna basarsi sui
modelli per PLTL.
\begin{definizione}(Suffisso)\\
  Preso un cammino:
  \[\pi = q_0, q_1, q_2, \dots q_n\]
  Si dice \textbf{suffisso di ordine $i$ di $\pi$} un cammino:
    \[\pi^{(i)} = q_i, q_i+1, \dots q_n\]
  
\end{definizione} \vspace{5mm} %5mm vertical space
\subsubsection{Interpretazione di LTL su un modello di Kripke}
Precediamo in due fasi:
\begin{enumerate}
    \item definiamo un criterio per stabilire se una formula $\alpha$ è vera in un
cammino massimale $\pi$.
\item diciamo che la formula è vera rispetto a uno stato q se è vera in tutti
i cammini massimali che partono da q
\end{enumerate}
\begin{definizione}
  Diciamo anche che una formula è vera rispetto ad uno stato $q$ del modello di
  Kripke se è vera in tutti i cammini \textbf{massimali} $\pi$ che partono da $q$,
  dicendo che la formula $\alpha$ è soddisfatta in $\pi$.\\
  Per comodità indichiamo un cammino massimale generico con:
  \[\pi=q_0q_1\ldots q_n\]
  e un suffisso di ordine $i$:
  \[\pi^{(i)}=q_iq_{i+1}\ldots q_j\]
  La formula è vera rispetto ad uno stato $q$ del modello di Kripke se è vera in
  tutti i cammini a partire da $q$.\\
  Si indica con:
  \[\pi\vDash\alpha\]
  per indicare che $\alpha$ è vera/valida in $\pi$ (o che $\pi$ soddisfa
  $\alpha$).\\
\end{definizione} \vspace{5mm} %5mm vertical space
\subsubsection{Operatori di base}
  Se pensiamo ai modelli di Kripke si ha, dati $\alpha,\beta$ due formule e $p$
  una proposizione atomica:
  \begin{enumerate}
    \item $\pi\vDash p$ sse $p\in I(q_0)$, con $q_0$ stato iniziale scelto
    \item $\pi\vDash \neg \alpha$  sse $\pi\not\vDash \alpha$
    \item $\pi\vDash \alpha\lor\beta$ sse $\pi\vDash \alpha$ o $\pi\vDash \beta$
  \end{enumerate}
  Potenzialmente bastano questi due connettivi per definire tutti gli altri per
  la logica proposizionale. 
  \subsubsection{Operatori temporali}
  Passando agli operatori temporali, con $\alpha\in FBF$ (formule ben formate)
  si ha:
  \begin{enumerate}
    \item $\pi\vDash\mathbf{X}\,\alpha$ sse $\pi^{(1)}\vDash \alpha$ (quindi se
    nello stato successivo vale $\alpha$)
    \item $\pi\vDash\mathbf{F}\,\alpha$ sse $\exists
    i\in\mathbb{N}:\pi^{(i)}\vDash  \alpha$ quindi prima o poi $\alpha$ sarà
    vera (quindi può anche essere vera nello stato iniziale con $i=0$)
    \item $\pi\vDash\mathbf{G}\,\alpha$ sse $\forall\, i\in
    \mathbb{N}:\pi^{(i)}\vDash \alpha$, quindi $\alpha$ deve essere vero in
    tutti i suffissi di $\pi$ (e quindi anche nello stato iniziale)
    \item $\pi\vDash\alpha\,\mathbf{U}\,\beta$ sse 
    \begin{itemize}
        \item $\pi^{(i)}\vDash \beta$ (che
    sarebbe $\pi\vDash\mathbf{F}\,\beta$)
    \item  $\forall\, h\,\,\,\,\,\, 0\leq
    h<i,\,\,\, \pi^{(h)}\vDash \alpha$
    \end{itemize}
    Quindi esiste uno stato $i$ dove vale
    $\beta$ e in tutti gli stati precedenti (escluso $i$) vale $\alpha$.
    \begin{nota}
        Se $h=0$ allora la formula è sempre vera. Non esistendo valori $h$ allora $\alpha$ è vera sempre indipendentemente dagli stati.
    \end{nota}
  \end{enumerate}
% \textbf{Vedere anche esempio su slide.}\\
% \begin{esempio}
%   Graficamente si ha qualcosa del tipo:
%   \begin{figure}[H]
%     \centering
%     \includegraphics[scale = 0.263]{img/pltl.png}
%   \end{figure}
%   \textbf{che prosegue infinitamente}. Si nota che in ogni stato si specifica
%   se 
%   una variabile proposizionale (che sono infinite) è soddisfatta e, per
%   ciascuna 
%   variabile, si definisce una sorta di \textit{tabella di verità}, che
%   specificare la soddisfacibilità di una variabile in un determinato stato
% \end{esempio}
Si nota che la definizione di \textbf{modello PLTL} non esclude che due stati
diversi possano soddisfare le stesse variabili, ovvero che si possano comportare
nello stesso modo \textit{(come se nulla cambiasse nel tempo)}.
\begin{esempio}
  \includepdf{img/ltl.pdf}
\end{esempio}
\begin{esempio}
  Vediamo degli esempi (considerando cammini infiniti):
  \begin{itemize}
    \item $\mathbf{FG}\,\alpha$ indica che $\alpha$ è invariante da un certo
    punto in poi
    \item $\mathbf{GF}\,\alpha$ indica che $\alpha$ è vera in un numero infinito
    di stati (ma non necessariamente tutti)
    \item $\mathbf{G}(cs_1\land cs_2)$ è la mutua esclusione, avendo $cs_1$
    e $cs_2$ per indicare che il processo 1 e 2 sono rispettivamente in sezione
    critica 
    \item $\mathbf{G}\neq(req\implies\mathbf{XF}\, ack)$, avendo $req$ richiesta
    pendente di un server e $ack$ aknowledge, per dire che se si ha una
    richiesta pendente prima o poi si avrà il messaggio di ack subito dopo la
    req (non avviene in contemporaneamente ma nello stato dopo)
    \item $\mathbf{G}(req\implies(req\,\mathbf{U}\, ack))$ per dire che è sempre
    vero che se si ha una richiesta da un certo punto in poi si dovrà avere un
    ack, con la req che rimane vera fino al momento prima dell'ack
    \item $\mathbf{G}(req\implies((req\land \neg ack)\,\mathbf{U}\,(ack\land\neg
    req)))$ per dire che se abbiamo una richiesta pendente posso avere che resti tale
    fino all'ack ma quando arriva l'ack la req deve essere ``negativizzata''
    (non serve il next perché tanto non possono valere nello stesso stato per
    come è stata scritta la formula)
  \end{itemize}
\end{esempio}
\begin{esempio}
  Presa la rete:
  \begin{figure}[H]
    \centering
    \includegraphics[scale = 0.5]{img/mc.jpg}
  \end{figure}
  con al mutua esclusione, avendo:
  \begin{itemize}
    \item $rd$ la risorsa disponibile
    \item $sc1$ e $sc2$ le due sezioni critiche
    \item $snc1$ e $snc2$ le due sezioni non critiche
    \item $req1$ e $req2$ le due richieste pendenti di usare la risorsa
  \end{itemize}
  avendo il grafo dei casi (ipotizzando per semplicità $1$ come stato iniziale):
  \begin{figure}[H]
    \centering
    \includegraphics[scale = 0.7]{img/mc2.jpg}
  \end{figure}
  con:
  \begin{itemize}
    \item $1=\{rd, snc1, snc2\}$
    \item $2=\{rd, req1, snc2\}$
    \item $3=\{rd, snc1, req2\}$
    \item $4=\{rd, req1, req2\}$
    \item $5=\{sc1, snc2\}$
    \item $6=\{snc1, sc2\}$
    \item $7=\{sc1, req 2\}$
    \item $8=\{req1, sc2\}$
  \end{itemize}
  che può essere letto come modello di Kripke, con l'elenco sopra che può
  essere visto come la funzione di interpretazione dello stesso.\\
  Studiamo $\mathbf{G}\neq (cs_1\land cs_2)$ e $\mathbf{G}\,(req1\implies
  \mathbf{F}\, sc1)$ (è sempre vero che se vale $req1$ allora prima o poi la
  richiesta verrà soddisfatta).\\
  Per la prima formula possiamo dire che è una \textbf{proprietà di safety},
  esprimendo che non si può raggiungere uno stato ``pericoloso'', come l'uso
  contemporaneo della risorsa. La verifico anche solo scorrendo le
  interpretazioni degli stati e vedendo che non esiste uno stato in cui
  compaiono sia $sc1$ che $sc2$ (questo perché abbiamo il globally e basta quindi
  vale semplicemente per tutti gli stati). \\
  Non posso fare lo stesso per la seconda. abbiamo sempre una globally con quindi
  una proprietà invariante ma abbiamo all'interno un altro operatore temporale
  quindi non posso semplicemente scorrere la lista delle interpretazioni degli
  stati. In ogni caso questa seconda formula non è valida in quando potrei
  avere $(1)(2, 4, 8)^\omega$ in cui anche il secondo processo fa richiesta e ci
  entra. Posso entrare in un loop in cui solamente il processo
  due prende ogni volta la risorsa quindi la formula non è valida in quel
  cammino massimale.\\
  Possiamo comunque trovare cammini in cui vale, come $(1, 3, 6)^\omega$, in
  quanto in quei tre stati $req1$ è sempre falsa.
\end{esempio}
Introduciamo nuovi operatori temporali:
\begin{itemize}
  \item \textbf{weak until}:
  \[\alpha\,\mathbf{W}\,\beta\equiv \mathbf{G}\,\alpha\lor
    (\alpha\,\mathbf{U}\,\beta)\]
  quindi vale se $\alpha$ è sempre vera o se vale l'until classico
  \item \textbf{release}:
  \[\alpha\,\mathbf{R}\,\beta\mbox{ sse }\forall\, k\geq 0:(\pi^{(k)}\vDash
    \beta\lor \exists\, h<k:\pi^{(h)}\vDash \alpha)\]
  ovvero:
  \[\alpha\,\mathbf{R}\,\beta\equiv \beta\,\mathbf{W}\,(\alpha\land \beta)\]
  ovvero vale se $\beta$ è sempre vero o ad un certo punto $\beta$ è vero e
  diventa vero anche $\alpha$ e dall'istante successivo $\beta$ può diventare
  falso. Praticamente $\alpha$ libera $\beta$, che negli istanti successivi può
  essere falsa
\end{itemize}
\begin{nota}
    Per tradurre un enunciato in linguaggio naturale in logica temporale per
  prima cosa, occorre individuare le proposizioni atomiche; in seguito si
  analizza la struttura della frase, eventualmente riformulandola in una frase
  equivalente con espressioni corrispondenti agli operatori temporali.
\end{nota}
  \subsubsection{Equivalenza di Formule}
\begin{definizione}
Due formule sono equivalenti se quando una di esse è vera allora è vera anche l'altra.
  Definiamo l'equivalenza tra due formule come:
  \[\alpha\equiv \beta\iff \forall\,\pi:(\pi\vDash\alpha\leftrightarrow\pi\vDash
    \beta)\]
  \begin{nota}
      Quindi varia il modo per esprimere la stessa cosa. Per
  ogni cammino, $\alpha$ è soddisfatta sse lo è anche $\beta$ (e
  avendo il sse vale anche il viceversa).
  \end{nota}
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{esempio}
  Vediamo esempi di formule equivalenti:
  \begin{itemize}
    \item $\mathbf{F}\,\alpha\equiv\alpha\lor\mathbf{XF}\,\alpha$\\
    Ovvero: se $\alpha$ è vera in $q_0$ o sarà vera prima o poi in uno stato futuro.
    \item $\mathbf{G}\,\alpha\equiv\alpha\land\mathbf{XG}\,\alpha$\\
    infatti dire che vale sempre $\alpha$ è come dire che ora vale $\alpha$ e
    che nel prossimo stato vale il globally di $\alpha$
    \item $\alpha\mathbf{U}\,\beta\equiv\beta\lor(\alpha\land
    \mathbf{X}\,(\alpha\,\mathbf{U}\,\beta)$ \\
    ovvero l'until è equivalente a dire che ora vale $\beta$ o che ora vale
    $\alpha$ ma nello stato successivo varrà l'until
  \end{itemize}
 \end{esempio}
\begin{nota}
      Si evidenzia in tutti e tre i casi la natura ricorsiva delle formule della
  logica temporale.
\end{nota}
\begin{esempio}
  Vediamo infatti altri esempi:
  \begin{itemize}
    \item $\mathbf{FGF}\,\alpha\equiv\mathbf{GF}\,\alpha$
    quindi aggiungere il primo future in \textbf{\textit{FGF}} è inutile
    \item $\mathbf{GFG}\,\alpha\equiv\mathbf{FG}\,\alpha$
    quindi aggiungere il primo globally in \textbf{\textit{GFG}} è inutile   
  \end{itemize}
\end{esempio}
\subsubsection{Insiemi minimali di operatori}
Partendo da un insieme minimale di operatori possiamo derivare tutti gli altri.
\begin{esempio}
Prendiamo la formula:
\[\top\,\mathbf{U}\,\alpha\]
ma per definizione ci basta dire che $\alpha$ prima o poi diventi vera e
quindi basta:
\[\top\,\mathbf{U}\,\alpha\equiv F\alpha\]
Da questo esempio deriviamo che: \textbf{Il future può sempre essere rappresentato dall'until}.
\end{esempio}
\begin{esempio}
  Vediamo un altra formula:
\[\neg\mathbf{F}\,(\neg\alpha)\]
ma questo equivale a dire:
\[\neg\mathbf{F}\,(\neg\alpha)=\mathbf{G}\,\alpha\]
Quindi il globally può essere derivato dal future che è derivato dall'until e
quindi \textbf{anche il globally potrebbe essere rimosso}.\\
\end{esempio}
\begin{nota}
      Si può dimostrare che il \textbf{next non è derivabile} e che \textbf{l'until, a
  sua volta, non è derivabile}.
\end{nota}
\begin{definizione}
  Definiamo un \textbf{insieme minale di operatori}. L'insieme
  $\{\mathbf{X},\mathbf{U}\}$ forma un insieme minimale di operatori, dal quale
  possiamo derivare tutti gli altri (\textbf{\textit{F, G, W, R}}).\\
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{nota}
  Potenzialmente potrei quindi usare solo until e next.
      Si hanno anche altri insiemi minimali di operatori volendo (ma in tutti ci
  sarà l'until essendo l'unico operatore binario, non potendo derivarlo da uno
  unario). 
\end{nota}
\noindent
\subsubsection{La negazione in LTL e le formule “esistenziali”}
Studiamo ora meglio la negazione di connettivi logici. Forniamo alcuni esempi\\
\begin{itemize}
    \item Pensiamo a ``non è vero che $\mathbf{F}\,\alpha$''. Possiamo riformularla con
``Non è vero che in ogni cammino, prima o poi $\alpha$ diventi vera'', cioè
``esiste un cammino nel quale $\alpha$ è sempre falsa''.
    \item D'altro canto
$\neg\mathbf{F}\,\alpha$ significa ``in ogni cammino non è vero che prima o poi
$\alpha$ diventi vera'' (che equivale a $\mathbf{G}\,(\neg \alpha)$) 
\end{itemize}
Quindi in realtà $\neg\mathbf{F}\,\alpha$ non è la negazione logica di $\mathbf{F}\,\alpha$ perché nasconde il concetto di ``per ogni cammino'', con
quindi il quantificatore $\forall$. Dalla logica predicativa sappiamo che la
negazione di una formula dove compare un quantificatore equivale a cambiare il
quantificatore e aggiungere la negazione e quindi la riformulazione giusta
sarebbe ``esiste un cammino in cui vale $\mathbf{F}\,\alpha$'', che non può
essere rappresentato in logica temporale LTL. Si ha
quindi un limite 
espressivo, non può esprimere proprietà del tipo:
\begin{center}
  \textbf{\textit{esiste un cammino in cui $\alpha$}}
\end{center}
\begin{esempio}
  Vediamo esempi di proprietà di questo tipo:
  \begin{itemize}
    \item ``è sempre possibile ritornare allo stato iniziale''
    (``è possibile'' si traduce in ``esiste un cammino'')
    \item ``e il processo $P$ chiede la risorsa, è possibile raggiungere uno
    stato di deadlock'' 
  \end{itemize}
\end{esempio}
\begin{esempio}
  Si prenda:
  \begin{figure}[H]
    \centering
    \includegraphics[scale = 0.4]{img/kri.jpg}
  \end{figure}
  che è un modello di Kripke che rappresenta le evoluzioni di un programma con
  due variabili $x$ e $y$. I vari $q_i$ rappresentano i possibili stati.\\
  Studiamo:
  \begin{itemize}
    \item $\mathbf{G}\,(x=0\lor y=0)$
    \item $\mathbf{GF}\,(y=0)$
    \item $\mathbf{GF}\,(y=1)$
    \item $\mathbf{G}\,(x=1\implies \mathbf{F}\,(y=1))$
  \end{itemize}
  per farlo bisogna studiare ogni possibile evoluzione a partire da ogni stato
  (che di volta in volta diventa uno stato iniziale).
  \begin{itemize}
    \item $\mathbf{G}\,(x=0\lor y=0)$: per il primo basta osservare i vari stati e osservare che vale
    l'argomento del globally in ogni stato, quindi qualsiasi sia lo stato
    iniziale varrà il globally (visto che passo in stati in cui vale sempre
    l'argomento) e quindi la formula è verificata
    \item $\mathbf{GF}\,(y=0)$: parto dalla formula più interna (dopo aver valutato dove vale
    l'argomento, ovvero in $q_1$ e $q_2$), ovvero il future, e studiare dove
    vale. Per proprietà del future vedo che posso partire da $q_1$ e dire che
    vale (dato che vale anche in $q_1$ stesso), posso partire da $q_2$ per lo
    stesso ragionamento di $q_1$. Ragiono ora su $q_3$, dove non vale $y=0$, ma
    da lui parte un solo arco e porta in uno stato dove vale $y=0$ quindi ogni
    cammino che parte da $q_3$ soddisfa $y=0$. Il future vale quindi in ogni
    stato e di conseguenza anche il globally e quindi la formula è verificata
    \item $\mathbf{GF}\,(y=1)$: ragiono come per il caso 2. Per $q_3$ vale ovviamente il future. Passo
    a $q_1$ e già qui vedo che potrei avere un cammino massimale con solo $q_1$
    e $q_2$ e quindi non vale il future. Analogamente si fa lo stesso per $q_2$,
    che non soddisfa il future. Il globally quindi non vale in $q_1$ e $q_2$,
    non valendo lì il future. Studiamo ora $q_3$ ma anche qui non vale in quanto
    potrei, in uno dei cammini da $q_3$ entrare nel loop tra $q_1$ e $q_2$,
    quindi anche per $q_3$ non vale il globally e quindi la formula non è
    verificata    
    \item $\mathbf{G}\,(x=1\implies \mathbf{F}\,(y=1))$: prendiamo il cammino che parte da $q_1$ e cicla infinitamente con $q_3$ e
    $q_2$, in questo cammino la formula è verificata. In ogni cammino in qui da
    $q_1$ passo a $q_3$ la formula è verificata ma non lo è nel solito loop tra
    $q_1$ e $q_2$ e quindi la formula non è verificata
  \end{itemize}
\end{esempio}
\begin{esempio}
  Studiamo il modello di Kripke della mutua esclusione:
  \begin{figure}[H]
    \centering
    \includegraphics[scale = 0.7]{img/mc2.jpg}
  \end{figure}
  \noindent
  con:
  \begin{itemize}
    \item $1=\{rd, snc1, snc2\}$
    \item $2=\{rd, req1, snc2\}$
    \item $3=\{rd, snc1, req2\}$
    \item $4=\{rd, req1, req2\}$
    \item $5=\{sc1, snc2\}$
    \item $6=\{snc1, sc2\}$
    \item $7=\{sc1, req 2\}$
    \item $8=\{req1, sc2\}$
  \end{itemize}
  avendo:
  \begin{itemize}
    \item $rd$ la risorsa disponibile
    \item $sc1$ e $sc2$ le due sezioni critiche
    \item $snc1$ e $snc2$ le due sezioni non critiche
    \item $req1$ e $req2$ le due richieste pendenti di usare la risorsa
  \end{itemize}
  Si richiede:
  \begin{itemize}
    \item i due processi non sono mai contemporaneamente nella sezione critica
    \item se un processo richiede la risorsa, prima o poi entrerà nella sezione
    critica, escludendo la starvation
    \item se un solo processo richiede la risorsa, deve poter accedere alla
    sezione critica
  \end{itemize}
  Esprimiamo ciò in logica temporale:
  \begin{itemize}
    \item $\mathbf{G}\,\neg(sc1\land sc2)$
    \item $\mathbf{G}\,(req1\implies \mathbf{F}\, sc1)$
    \item non è esprimibile in logica temporale in quanto esprime una
    possibilità 
  \end{itemize}
  Studiamo quindi, informalmente i primi due requisiti:
  \begin{itemize}
    \item la prima proprietà è verificata non avendo stati dove valgono
    contemporaneamente i due argomenti
    \item la seconda non è verificata avendo un cammino massimale
    $(1)(2, 4, 8)^\omega$ che impedisce al primo processo di entrare in sezione
    critica (c'è anche un cammino massimale dove non entra mai il secondo)
  \end{itemize}
  Intuitivamente posso ragionare anche sul terzo requisito possiamo dire che è
  valida in quanto può accedere infinitamente alla risorsa con l'altro che non
  cerca mai di accederci.\\
  Per validare anche la seconda formula possiamo ricordarci l'ultimo accesso e
  in caso di conflitto dare priorità sull'altro accesso. Nel modello di Kripke
  avremmo: 
  \begin{figure}[H]
    \centering
    \includegraphics[scale = 0.6]{img/mc3.jpg}
  \end{figure}
  dove lo stato 4 viene sdoppiato in 4 e 9, che hanno le stesse proposizioni
  atomiche, $rd, req1, re2$ ma da entrambi ora parte un singolo arco che
  rispettivamente porta dove l'altro processo è in pending, dandogli poi i
  privilegi di accesso. Si garantisce comunque la mutua esclusione, si soddisfa
  la seconda proprietà (garantendo alternanza di accesso).
\end{esempio}
\section{Computation tree logic (CTL)}
Il CTL è una forma di logica temporale, in particolare è una \textit{branch-time logic}, ciò implica che il suo modello di tempo sfrutta una struttura ad albero (\textit{alberi di computazione}) in cui il futuro non è determinato. Esistono diverse ramificazioni dell'albero stesso che indicano \textit{"il futuro"} ognuno dei quali potrebbe essere un percorso reale che si realizza.
Studiamo ora \textbf{alberi di computazione} derivati da modelli di Kripke.
\begin{esempio}
  Prendiamo il modello:
  \begin{figure}[H]
    \centering
    \includegraphics[scale = 0.4]{img/kri.jpg}
  \end{figure}
  Scegliamo come nodo iniziale $q_1$ e costruiamo un albero che rappresenta le
  possibili computazioni:
  \begin{figure}[H]
    \centering
    \includegraphics[scale = 0.4]{img/mc4.jpg}
  \end{figure}
\end{esempio}
\begin{definizione}
  Propriamente definiamo \textbf{computazione} un cammino dell'albero a partire
  dalla radice.
\end{definizione} \vspace{5mm} %5mm vertical space
Passiamo ora alla sintassi delle formule ben formate della \textbf{Computational
  Tree Logic (\textit{CTL})}.
\begin{definizione}
  Si ha che, dato $AP$ insieme delle proposizioni atomiche:
  \begin{itemize}
    \item $\forall p\in AP, p\in FBF$
    \item $\forall\,\alpha,\beta\in FBF$ valgono gli operatori della logica
    proposizionale 
  \end{itemize}
  Aggiungiamo ora i nuovi connettori, \textbf{\textit{A}} e \textit{\textbf{E}},
  che si associano ai connettivi temporali:
  \begin{itemize}
    \item $\mathbf{A}$ indica il ``per ogni cammino''
    \item $\mathbf{E}$ indica il ``esiste almeno un cammino tale che''
  \end{itemize}
  \begin{nota}
    Questi operatori possono precedere un solo operatore temporale per
    volta e ogni operatore temporale deve essere preceduto da un
    quantificatore.
  \end{nota}
  Si ha quindi che:
  \begin{itemize}
    \item $\mathbf{AX}\,\alpha,\mathbf{EX}\,\alpha\in FBF$
    \item $\mathbf{AF}\,\alpha,\mathbf{EF}\,\alpha\in FBF$
    \item $\mathbf{AG}\,\alpha,\mathbf{EG}\,\alpha\in FBF$
    \item $\mathbf{A}\,(\alpha\,\mathbf{U}\,\beta),\,\mathbf{E}\,
    (\alpha\,\mathbf{U}\,\beta)\in FBF$    
  \end{itemize}
\begin{nota}
    Si hanno formule, come $\mathbf{AFG}\,\alpha$, che non sono una formula CTL. 
\end{nota}
\begin{nota}
 Si hanno formule LTL che non sono formule CTL, e viceversa.
\end{nota}
\end{definizione} \vspace{5mm} %5mm vertical space
\subsection{CTL - Semantica}
\begin{definizione}
  Sia M = (Q, T, I) un modello di Kripke, $\alpha$ una formula di CTL, q uno stato di M. Allora
\[M,q \vDash \alpha\]
significa che $\alpha$ è vera nello stato q del modello M
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{nota}
 Definiamo la relazione $\vDash$ per induzione sulla struttura delle formule
\end{nota}
Quindi al contrario di LTS, stiamo controllando il valore di verità di una formula in un singolo stato. In particolare supponiamo che $\alpha$ e $\beta$ siano due formule, $p$ una proposizione atomica, allora:
 \begin{enumerate}
    \item $M,q\vDash p$ sse $p\in I(q)$, con $q$ stato iniziale scelto
    \item $M,q\vDash \neg \alpha$  sse $M,q\not\vDash \alpha$
    \item $M,q\vDash \alpha\lor\beta$ sse $M,q\vDash \alpha$ o $M,q\vDash \beta$
    \item $M,q$  $\vDash$ AX$\alpha$ sse per ogni q' tale che q $\implies$ q', $M,q$ ' $\vDash$ $\alpha$
    \item $M,q$  $\vDash$ EX$\alpha$ sse esiste q' tale che q $\implies$ q' e $M,q$ ' $\vDash$ $\alpha$
    \item $M,q$  $\vDash$ AU($\alpha$, $\beta$) sse per ogni cammino q = ${q_0, q_1, \dots}$ esiste k $\geq$ 0 tale che $M,q_k$  $\vDash$ $\beta$, e per ogni $ 0 \leq i < k$ $\,\,\,\,M,q_i \vDash \alpha$
  \end{enumerate}
 \subsection{Esempi}
 \includepdf[pages=-]{img/CTSEsercizi.pdf}
 \subsection{Confronto CTL e LTL}
Si ha che molte proprietà possono essere espresse sia in PLTL che in CTL:
\begin{itemize}
  \item \textbf{proprietà invarianti}, con $\mathbf{G}\,\alpha$ e con
  $\mathbf{AG}\,\alpha$ in CTL
  \item \textbf{proprietà di reattività} (proprietà invarianti condizionali),
  con $\mathbf{G}\,(\alpha\implies \mathbf{F}\,\beta)$ e con
  $\mathbf{AG}\,(\alpha\implies \mathbf{AF}\,\beta)$ in CTL
\end{itemize}
Ma si hanno anche proprietà non rappresentabili. Prendiamo ad esempio la
\textbf{reset property}:
\[\mathbf{AG}\,\mathbf{EF}\,\alpha\]
ovvero: \textit{"da ogni stato raggiungibile in ogni cammino è sempre possibile
  raggiungere uno stato nel quale vale $\alpha$}". \\Questa non può essere espressa
in LTL ma solo in CTL.\\
Vediamo una formula che può essere espressa solo in PLTL:
\[\mathbf{FG}\,\alpha\]
ovvero:\textit{"in ogni cammino, prima o poi si raggiungerà uno stato a partire
  dal quale $\alpha$ rimane sempre vera"}.\\ Questa non può essere espressa
in CTL (se  prendiamo l'albero abbiamo cammini in cui non è vero che $\alpha$ rimane
sempre vero) ma solo in PLTL.\\
\subsubsection{Dimostrazione per Confronto}
 \includepdf[pages=-]{img/CTSConfronto.pdf}

\begin{nota}
Si ha un'estensione di CTL e PLTL, detta CTL$^*$, nella quale si mantengono i
quantificatori sui camini ma si elimina il vincolo CTL per il quale ogni
operatore temporale deve avere un quantificatore (posso quindi avere formule del
tipo $\mathbf{EFG}\,\alpha$).\\ 
Potrei avere formule di CTL$^*$ che non sono esprimibili in CTL e
PLTL, estendendone la capacità espressiva ma aumentando la complessità degli
algoritmi associati. In pratica l'insieme delle formule CTL$^*$ contiene gli
altri due (che per di più hanno un'intersezione tra loro). 
\end{nota}
\section{Model checking}
\begin{definizione}
  Due modelli di Kripke $M_1$ e $M_2$ con stati iniziali $q_0$ e $s_0$, si ha
  che essi sono \textbf{equivalenti} rispetto ad una logica $I$ (che può essere
  PLTL, CTL etc$\ldots$) se, per ogni formula $\alpha\in FBF_I$, si ha:
  \[M_1, q_0\vDash \alpha\iff M_2, s_0\vDash \alpha\]
  Avendo che i due modelli sono effettivamente indistinguibili.\\
  L'equivalenza è quindi in funzione di proprietà della logica stessa.\\
\end{definizione} \vspace{5mm} %5mm vertical space
\subsection{Insiemi parzialmente ordinati}
Una relazione d'ordine parziale afferma che non tutti gli elementi di un determinato insieme possono essere \textbf{confrontati}. In generale, due elementi di una relazione d'ordine parziale possono non essere confrontabili, cioè non sono necessariamente in relazione fra di loro. Ad esempio in $\mathbb{N} \backslash \{0\}$ munito della relazione di divisibilità, gli elementi 2 e 3 non sono in relazione perché nessuno dei due è divisore dell'altro. 
\begin{definizione}
  Due elementi $a$ e $b$ di un insieme parzialmente ordinato $( A , \leq )$ si dicono confrontabili se accade che  $a\leq b$ oppure $b\leq a$. 
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{definizione}
  Si ha che una relazione parziale $\leq$ su $A$:
  \[\leq\,\,\, \subseteq A\times A\]
  è:
  \begin{itemize}
    \item \textbf{riflessiva}, infatti $x\leq x,\,\,\,\forall\, x\in A$ 
    \item \textbf{antisimmetrica}, infatti $(x\leq y\,\,\land\,\, y\leq
    x)\implies  x=y,\,\,\,\forall x, y\in A$
    \item \textbf{transitiva}, infatti $(x\leq y\,\,\land\,\, y\leq z)\implies
    x\leq z,\forall\, x, y, z\in A$
  \end{itemize}
  \begin{nota}
  La notazione:
  \[x<y\]
  significa;
  \[x\leq y\,\,\land\,\, x\neq y\]
  \end{nota}
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{definizione}
  Dato $(A,\leq)$ un insieme parzialmente ordinato e $B\subseteq A$ si
  definiscono:
  \begin{itemize}
    \item $x\in A$ è un \textbf{maggiorante} di $B$ se $y\leq
    x,\,\,\,\forall\, y\in B$
    \item $x\in A$ è un \textbf{minorante} di $B$ se $x\leq
    y,\,\,\,\forall\, y\in B$
    \item $B^*$ come \textbf{insieme dei maggioranti di $B$}
    \item $B_*$ come \textbf{insieme dei minoranti di $B$}
    \item $B$ è \textbf{superiormente limitato} se $B^*\neq \emptyset$
    \item $B$ è \textbf{inferiormente limitato} se $B_*\neq \emptyset$
    \item $x\in B$ è il \textbf{minimo} di $B$ se $x\leq y,\,\,\,\forall\, y\in
    B$ 
    \item $x\in B$ è il \textbf{massimo} di $B$ se $y\leq x,\,\,\,\forall\, y\in
    B$
    \item $x\in B$ è il \textbf{minimale} di $B$ se $y\leq x\implies y=x$
    \item $x\in B$ è il \textbf{massimale} di $B$ se $x\leq y\implies y=x$
  \end{itemize}
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{definizione}
  Si ha che:
  \begin{itemize}
    \item se $x$ è il minimo di $B^*$ allora $x$ è l'\textbf{estremo superiore
      (join)} di $B$:
    \[x=\sup B=\bigvee B\]
    \item se $x$ è il massimo di $B_*$ allora $x$ è l'\textbf{estremo inferiore
      (meet)} di $B$:
    \[x=\inf B=\bigwedge B\]
  \end{itemize}
\begin{corollario}
  Se $B=\{x, y\}$ si ha che $x\lor y$ indica $\bigvee B$ (se
  esiste) e $x\land y$ indica $\bigwedge B$ (se esiste).
\end{corollario}
\end{definizione}
\vspace{5mm} %5mm vertical space
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{img/maggioranti.png}
    \caption{Esempio Maggiorante e Estremo Superiore}
\end{figure}
\begin{esempio}
Documentiamo alcuni esempi:
  \begin{itemize}
      \item $(2^{A}, \subseteq )$ con $A$ un insieme qualsiasi.
      \begin{itemize}
          \item Riflessiva: ogni insieme $2^A\,\,\, \forall A$ è contenuto in se stesso.
          \item Antisimmetrica
          \item Transitiva
      \end{itemize}
      In questo insieme $A$ è l'elemento massimo e $\emptyset$ è quello minimo. \\ 
      Presi due sottoinsiemi di $A$ esiste un \textit{join} e un \textit{meet} tra loro. In particolare il \textit{join} sarebbe un estremo superiore che è più grande di questi due, cioè contiene questi due sottoinsiemi, ma è piu piccolo di \textbf{tutti gli altri} sottoinsiemi che li contengono. Si noti che l'insieme dato dall'unione contiene tutti i sottoinsieme di partenza ed è più piccolo rispetto agli altri. Simmetricamente l'operazione di \textit{meet} riguarda l'intersezione.
      \item $(\mathbb{N^+}, |)$. 
      \begin{itemize}
          \item Riflessiva: ogni numero divide se stesso
          \item Antisimmetrica: \textbf{non} posso avere due numeri $x\neg y$ con la proprietà che $x/y$ e $y/x$.
          \item Transitiva.
      \end{itemize}
      Il numero 1 è il valore più piccolo poiché divide tutti gli altri, sebbene non esista un massimo. \\
      Dati due numeri appartenenti all'insieme $\mathbb{N^+}$:
      \begin{itemize}
          \item Il \textit{meet} riguarderebbe un numero che divide entrambi ed è più grande di ciascun numero che li divide entrambi: il \textit{massimo comune divisore}.
          \item il \textit{join} riguarda analogamente il \textit{minimo comune multiplo}.
      \end{itemize}
      \item $([FBF_{LP}]_\equiv, \implies )$: ovvero l'\textbf{implicazione} tra \textbf{classi di equivalenza} di formule di una logica proposizionale. \\ 
      La classi di equivalenza di $\alpha$ e minore o uguale della classe di equivalenza di $\beta$ se vale la \textbf{relazione di inplicazione} tra un elemento qualunque della c.d.e di $\alpha$ e un elemento qualunque della c.d.e di $\beta$.
      \begin{itemize}
          \item Riflessiva: $\alpha \iff \alpha$ è una tautologia.
          \item Antisimmetrica: se $\alpha \implies \beta$ e $\beta \implies \alpha$ allora $\alpha \iff \beta$ quindi le formule $\alpha$ e $\beta$ sono nella stessa classi di equivalenza.
          \item Transitiva.
      \end{itemize}
      Il minimo è una formula che implica tutte le altre formule: la classe di equivalenza delle \textbf{contraddizioni}. La classe di equivalenza delle \textbf{tautologie} è l'elemento massimo.\\
      Date due classi di equivalenza:
      \begin{itemize}
          \item Join: Disgiunzione logica
          \item Meet: Congiunzione logica
      \end{itemize}
      \item Una rete di occorrenze: non sarebbe una relazione d'ordine parziale perché non è né transitiva né riflessiva, ma tramite la relazione $F\#$, ovvero la chiusura riflessiva e transitiva della relazione $F$.
      In particolare la chiusura riflessiva è tale se aggiungiamo ad una relazione tutte le coppie $(x,x)$, mentre quella transitiva è tale se esistono $(a,b);(b,c)$ per cui si può aggiungere $(a,c)$. Così facendo si parte dalla relazione di partenza e si aggiunge la transitività o la riflessività. Quindi \textbf{la relazione d'ordine in una rete di occorrenze è la chiusura riflessiva e transitiva della relazione di flusso della rete di occorrenze}.
  \end{itemize}
\end{esempio}
\subsubsection{Diagrammi di Hasse}
I diagrammi di Hasse servono a gestire graficamente le relazioni d'ordine. Si vuole inoltrare l'apprendimento di questa parte alla pagina appropriata: \url{https://it.wikipedia.org/wiki/Diagramma_di_Hasse}.
\subsection{Reticoli}
\begin{definizione}
  Definiamo \textbf{reticolo} un insieme parzialmente ordinato $(L,\leq)$ tale
  che, $\forall\, x, y\in L$ esistono $x\lor y$ e $x\land y$.
  \begin{nota}
  Per ogni coppia di elementi devono esistere l'estremo superiore e inferiore. Quindi \textit{join} e \textit{meet} esistono per ogni sottoinsieme finito.
  \end{nota}
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{definizione} 
  Definiamo \textbf{reticolo completo} se $\bigvee B$ e $\bigwedge B$ esistono
  per ogni $B\subseteq L$, eventualmente anche per sottoinsiemi  $B\subseteq L$ infiniti.
\end{definizione} \vspace{5mm} %5mm vertical space
\subsubsection{Insiemi parzialmente ordinati e funzioni monotòne}
\begin{definizione}
  Prendiamo due insiemi parzialmente ordinati $(A,\leq)$ e $(B,\leq)$, si ha che
  una funzione:
  \[f:A\to B\]
  è detta \textbf{monotona} se, $\forall\, x, y\in A$ vale:
  \[x\leq y\implies f(x)\leq f(y)\]
  ovvero se \textbf{preserva la relazione d'ordine}.\\
  Vale anche nel caso particolare in cui $A$ e $B$ coincidono.
\end{definizione} \vspace{5mm} %5mm vertical space
\subsubsection{Funzioni e punti fissi}
\begin{definizione}
  Prese in considerazione funzioni con dominio e codominio coincidenti, ovvero del tipo:
  \[f:X\to X\]
  si ha che un elemento $x\in X$ è un \textbf{punto fisso} di $f$ se:
  \[f(x)=x\]
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{esempio}
  Vediamo qualche esempio:
  \begin{itemize}
    \item $f:\mathbb{R}\to\mathbb{R}$, $f(x)=x^2$ e l'insieme dei punti fissi è
    $\{0, 1\}$ (si nota che la funzione non è monotona)
    \item $f:\mathbb{R}^+\to\mathbb{R}$, $f(x)=\log x$ e l'insieme dei punti
    fissi è $\emptyset$ (si nota che la funzione è monotona)
    \item $f:\mathbb{R}\to\mathbb{R}$, $f(x)=x$ (ovvero l'\textbf{identità}) e
    l'insieme dei punti fissi è $\mathbb{R}$ 
  \end{itemize}
\end{esempio}
Preso un insieme parzialmente ordinato $(A,\leq)$ e $f:A\to A$ monotona. Ci si
chiede se esistono un massimo e un minimo punto fisso.
\begin{esempio}
  Prendiamo $A=2^\mathbb{N}$ e $S\subseteq \mathbb{N}$. Vediamo vari esempi:
  \begin{itemize}
    \item $f(S)=S\cup\{2, 7\}$, una funzione monotona. Si ha che tutti i
    sottoinsiemi che contengono $2$ o $7$ sono punti fissi (ogni insieme delle
    parti di $\{2, 7\}$), tali sottoinsiemi
    sono anche i minimi punti fissi. Si ha un massimo punto fisso che è
    $\mathbb{N}$
    \item $f(S)=S\cap\{2, 7, 8\}$, una funzione monotona. Si ha che il
    sottoinsieme $\{2, 7, 8\}$ è un punto fisso. D'altro canto anche ogni insieme
    appartenente all'insieme delle parti di $\{2, 7, 8\}$ è punto fisso. Il
    massimo punto fisso è $\{2, 7, 8\}$ e come minimo punto fisso abbiamo
    $\emptyset$ 
  \end{itemize}
  Si nota una sorta di simmetria tra massimi e minimi punti fissi nel caso di
  unione o intersezione
\end{esempio}
\begin{esempio}
  Sia $A=\{1,\ldots, 11\}$ visti come stringhe e con questi 11 elementi si
  costruisca un albero binario orientato: 
  \begin{figure}[H]
    \centering
    \includegraphics[scale = 0.9]{img/tree.pdf}
  \end{figure}
  Prendiamo l'insieme
  $(\mathcal{P}(A),\subseteq)$ con $\mathcal{P}$ che indica l'insieme delle
  parti.\\
  Si ha:
  \[f:\mathcal{P}(A)\to \mathcal{P}(A)\]
  con:
  \[F(S)=S\cup\{x\in A|x\mbox{ è figlio di un }y\in S\}\]
  ad esempio:
  \[f(\{2, 6\})=\{2, 6, 4, 5, 10\}\]
  quindi $f(\{2, 6\})$ non è un punto fisso.\\
  Si ha anche che:
  \[f(\{2, 6, 4, 5, 10\})=\{2, 6, 4, 5, 10, 8, 9\}=M\]
  Ma quindi:
  \[f(M)=M\qquad f(\emptyset)=\emptyset\]
  I punti fissi di questa funzione sono i cosiddetti \textbf{insiemi chiusi
    verso il basso}, ovvero un insieme che se contiene un certo nodo contiene
  anche tutti i discendenti di quel nodo (ovvero tutti i sottoalberi
  discendenti).\\
  Il massimo punto fisso è $A$ stesso mentre il minimo punto fisso è l'insieme
  vuoto (ed esistono vari punti fissi minimali).
  \label{es:k}
\end{esempio}
\subsubsection{Teorema di Knaster-Tarski}
\begin{definizione}[Teorema di Knaster-Tarski]
  Sia $(L,\leq)$ un reticolo completo (quindi per ogni coppia si hanno
  \textit{join} e \textit{meet} e quindi ogni sottoinsieme finito di elementi di
  $L$ ha ancora \textit{join} e \textit{meet}, anche i sottoinsiemi infiniti) e
  $f:L\to L$ una funzione monotona. Si ha 
  in tal caso che $f$ ha un punto fisso minimo e un punto fisso massimo.\\
  Detto altrimenti l'insieme dei punti fissi forma un reticolo completo (e
  quindi necessariamente si ha un minimo e un massimo).\\
\end{definizione}
\begin{proof}
  Per semplicità consideriamo $L=\mathcal{P}(A)$ per un certo insieme $A$,
  sapendo che l'insieme delle parti è un reticolo completo (nonché un'algebra
  booleana).\\
  Sappiamo che $f:2^A\to 2^A$ (con $2^A$ che è $\mathcal{P}(A)$ è monotona).\\
  Costruiamo l'insieme:
  \[\mathcal{Z}=\{T\subseteq A|\, f(T)\subseteq T\}\]
  Chiamiamo gli elementi di $\mathcal{Z}$ \textbf{punti pre-fissi}. Si ha che
  $\mathcal{Z}$ non può essere vuoto qualsiasi sia $A$ (se reticolo) e qualsiasi
  sia $f$ (se monotona) in quanto contiene almeno gli elementi di $A$.\\
  Poniamo che $f$ abbia dei punti fissi. Si ha che $\mathcal{Z}$ conterebbe
  tutti questi punti fissi. Quindi $\mathcal{Z}$ contiene tutti i sottoinsiemi di A (che soddisfano la condizione), prendiamo in considerazione gli elementi comuni a tutti questi sottoinsiemi. \\
  Diciamo che:
  \[m=\bigcap \mathcal{Z}\]
  e si ha che $m\subseteq A$ ($m$ potrebbe essere $\emptyset$).\\
  Si ha che $\forall S\in \mathcal{Z}$ $m\subseteq S$ e , per la monotonia: 
  \[f(m)\subseteq f(S)\]
  ma quindi si ha che:
  \[f(m)\subseteq f(S)\subseteq S\]
  Quindi ogni immagine di $m$ è contenuta in $S$. Quindi non solo $m$ è contenuto in un generico elemento di $\mathcal{Z}$, bensì anche la sua immagine.\\
  Possiamo quindi dire che è contenuto nell'intersezione degli elementi di
  $\mathcal{Z}$: 
  \[f(m)\subseteq\bigcap \mathcal{Z}=m\]
  e quindi:
  \[m\in \mathcal{Z}\]
  e quindi $m$ è il minimo di $\mathcal{Z}$ (che non ha nemmeno elementi
  minimali che non contengono $m$). Quindi:
  \[m=\min\mathcal{Z}\]
  Quindi manca da dimostrare che $m$ sia un punto fisso.\\
  Ripartiamo da:
  \[f(m)\subseteq m\]
  avendo una relazione d'ordine tra due sottoinsiemi di $A$. MA avendo che $f$ è
  monotona posso dire che, applicando $f$ nuovamente:
  \[f(f(m))\subseteq f(m)\]
  e quindi $f(m)\in \mathcal{Z}$. Ma si ha anche che $m\subseteq f(m)$, avendo
  che $m=\min\mathcal{Z}$. Possiamo quindi concludere che:
  \[m=f(m)\]
  e quindi è un punto fisso.\\
  Concludendo abbiamo visto che $m$ è minimo ed è un punto fisso.\\
  Il ragionamento si può fare analogo e speculare per il massimo punto fisso.\\
\end{proof}
\begin{esempio}
  Riprendendo l'esempio \ref{es:k}, avendo una funzione monotona avendo dominio
  e codominio che sono reticoli completi (un reticolo finito è sempre completo),
  so sicuramente che ci sono un punto fisso massimo e uno minimo.
\end{esempio}
Questo definizione è poco utile dal punto di vista algoritmico, dovendo costruire
$\mathcal{Z}$ che può essere infinito.\\
Per lo più il model checking si fa su insiemi finiti ma con un numero di stati
magari enorme e quindi analizzare tutti i sottoinsiemi è poco pratico. Si ha
quindi un altro definizione.
\begin{definizione}[di Kleene]
  Sia $f:2^A\to 2^A$ una funzione monotona. Indicando con $X_i\subseteq 2^A$:
  \[X_1\subseteq X_2\subseteq\cdots\subseteq X_i\subseteq\cdots\]
  e si prendano le immagini:
  \[f(X_1)\subseteq f(X_2)\subseteq\cdots\subseteq f(X_i)\subseteq\cdots\]
  Tale funzione è \textbf{continua}
  se:
  \[f\left(\bigcup X_i\right)=\bigcup f(X_i)\]
  Se la funzione è continua allora possiamo affermare che:
  \begin{itemize}
    \item il minimo punto fisso di $f$ (che esiste per il definizione precedente)
    può essere calcolato con:
    \[f(\emptyset),\qquad f(f(\emptyset)),\qquad f(f(f(\emptyset))),
      \qquad\cdots\]
    calcolando lo ``step'' successivo fino ad arrivare ad un punto fisso
    arrivando prima o poi al minimo punto fisso 
    \item il massimo punto fisso di $f$ (che esiste per il definizione precedente)
    può essere calcolato con:
    \[f(A),\qquad f(f(A)),\qquad f(f(f(A))),\qquad\cdots\]
    arrivando prima o poi al massimo punto fisso (occhio che $A$ è quello di
    $2^A$) 
  \end{itemize}
\end{definizione}
\begin{esempio}
  Siano $A=2^{\mathbb{N}}$, $S\subseteq\mathbb{N}$ e $F(S)=S\cup \{2, 7\}$.\\
  Applico $f$ all'insieme vuoto e trovo $\{2, 7\}$ che non è punto fisso e quindi
  proseguo. Applico poi a $\{2, 7\}$ e ritrovo $\{2, 7\}$ che quindi è un punto
  fisso ed è il minimo. Per il massimo al primo step arrivo a dire che
  $\mathbb{N}$ è il massimo punto fisso (\textbf{non chiaro perché parte da
    $\mathbb{N}$ e non da $2^{\mathbb{N}}$}).  
\end{esempio}
\begin{esempio}
  \textbf{Su slide disegni dell'esempio.}\\
  Si supponga di avere un modello di Kripke e si vuole risolvere il model
  checking globale per $\mathbf{F}\, p$.\\
  Aggiungiamo tutti gli stati in cui in un solo step arriviamo sicuramente in
  uno stato dove vale $p$. \\
  Ora rifacciamo aggiungendo gli stati dove con uno step arriviamo sicuramente
  in uno stato dove vale $p$ o dove vale che allo step successivo sicuramente
  vale $p$. Procedo aumentando di volta in volta l'insieme ``buono'' fino a che
  non possiamo aggiungere nulla. Abbiamo trovato un minimo punto fisso
  dell'algoritmo. \\
  Valuto ora $\mathbf{G}\, p$ e ragiono all'inverso di come fatto prima
  escludendo di volta in volta gli stati in cui non vale $\mathbf{G}\, p$ (quindi
  l'insieme di partenza, diciamo, è quello in cui vale $\neg p$). Di volta in
  volta escludo gli stati che mi portano ad avere $\neg p$ più gli eventuali
  stati già inclusi nell'insieme in uno step precedente fino a che non abbiamo più
  passi possibili. Si arriva a trovare il massimo punto fisso.
\end{esempio}
\begin{definizione}
  Definiamo \textbf{automi di B\"{u}chi} come automi finiti che riconoscono
  parole infinite su un alfabeto $\Sigma$. Si indicano con la quadrupla:
  \[B=(Q, q_0,\delta, F)\]
  con:
  \begin{itemize}
    \item $Q$ insiemi di stati, detti \textit{locations}
    \item $q_0\in Q$ stato iniziale
    \item $\delta\subseteq Q\times \Sigma\times Q$ relazione di transizione
    \item $F\subseteq Q$ insieme di stati accettanti (non si può dire finali in
    quanto le stringhe sono infinite)
  \end{itemize}
  Presa quindi una parola infinita:
  \[w=a_0a_1\cdots\]
  essa è accettata da $B$ se la sequenza di stati corrispondente $q_0q_1\cdots$
  passa infinite volte per almeno uno stato di $F$. In altri termini mi fermo se
  uno stato non ha un arco uscente che porta alla lettera successiva altrimenti
  mi sposto in quello stato ma non serve che mi fermo in uno stato accettante ma
  è sufficiente passarci infinite volte.\\
  Diciamo che $L(B)$ è il linguaggio, ovvero l'insieme di tutte le parole
  accettate dalla'automa.
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{definizione}
  Il problema:
  \[L(B)=\emptyset\]
  è \textbf{decidibile}.
\end{definizione}
\begin{esempio}
  Sia:
  \begin{center}
    \begin{tikzpicture}[shorten >=1pt, node distance=2cm, on grid, auto]
      \node[state, initial, accepting] (q_0) {$q_0$};
      \node[state] (q_1) [right=of q_0] {$q_1$};
      \path[->]
      (q_0) edge  [bend left = 25]node {$a$} (q_1)
      (q_1) edge  [bend left = 25]node {$b$} (q_0)
      (q_0) edge [loop above] node {$b$} (q_0)
      (q_1) edge [loop above] node {$a$} (q_1)
      ;
    \end{tikzpicture}
  \end{center}
  Si ha:
  \begin{itemize}
    \item $w_1=bbbbbbbbb\cdots$ che è accettata
    \item $w_2=bbaaabbbb\cdots$ che è accettata
    \item $w_3=babababab\cdots$ che è accettata
    \item $w_4=baabbbaaa\cdots$ che non è accettata
  \end{itemize}
\end{esempio}
\begin{esempio}
  Studiamo la formula $\mathbf{GF}\, p$ e sia:
   \begin{center}
    \begin{tikzpicture}[shorten >=1pt, node distance=2cm, on grid, auto]
      \node[state, initial] (q_0) {$q_0$};
      \node[state, accepting] (q_1) [right=of q_0] {$q_1$};
      \path[->]
      (q_0) edge  [bend left = 25]node {$\{p\}$} (q_1)
      (q_1) edge  [bend left = 25]node {$\emptyset$} (q_0)
      (q_0) edge [loop above] node {$\emptyset$} (q_0)
      (q_1) edge [loop above] node {$\{p\}$} (q_1)
      ;
    \end{tikzpicture}
  \end{center}
  Immaginiamo qualche computazione:
  \begin{itemize}
    \item $w_1=\emptyset\{p\}\{p\}\emptyset\{p\}\emptyset\emptyset\cdots$ che
    non è accettata 
    \item $q_2=\emptyset\{p\}\emptyset\{p\}\emptyset\{p\}\emptyset\cdots$ che è
    accettata 
  \end{itemize}
  
\end{esempio}
Possiamo associare ad una computazione su un modello di Kripke una parola che
viene eseguita su un certo automa di di B\"{u}chi.\\
Un automa di B\"{u}chi corrisponde quindi ad una formula PLTL, ma bisogna notare
che l'insieme degli stati dell'automa non ha una relazione diretta con il
modello di Kripke.\\
Vediamo quindi l'algoritmo per vedere se una formula $\alpha$ è vera in
$(M, q_0)$:
\begin{itemize}
  \item costruiamo l'automa che verifica quando $\alpha$ non è verificata
  $B_{\neg\alpha}$ (non dimenticando i discorsi fatti in merito alla negazione
  in PLTL)
  \item trasformiamo $M$ in un automa etichettato come $B_{\neg\alpha}$ ovvero
  in un automa etichettato da insiemi diproposizioni atomiche 
  \item calcoliamo il prodotto sincrono dei due automi, che chiamiamo $PS$. Dati
  due automi definiti sullo stesso alfabeto il prodotto sincrono è un automa che
  corrisponde ad eseguire in parallelo i due automi in modo che procedano con le
  stesse etichette. Gli stati sono quindi il risultato del prodotto cartesiano
  tra gli stati dei due automi
  \item se $L(PS)=\emptyset$ allora $M, q_0\vDash\alpha$, in quando nel modello
  di Kripke $M$ non c'è nessun cammino infinito nel quale non è verificata
  $\alpha$, che quindi è valida nel modello di Kripke. Altrimenti si potrebbe
  eseguire un cammino in $M$ in cui non sarebbe soddisfatto $\alpha$ (si genera
  in caso anche un controesempio in cui la formula $\alpha$ è violata)
\end{itemize}
Passiamo ora cercare un algoritmo per CTL.
\begin{definizione}
  Fissiamo $M=(Q, T, I)$ e sia $\alpha$ una formula. Si definisce
  \textbf{estensione di $\alpha$}:
  \[[[\alpha]]=\{q\in Q|\, M, q\vDash \alpha\}\]
  Se $\alpha=\top$ estensione è l'insieme di tutti gli stati, se è $\bot$ è
  l'insieme vuoto. Se la formula è una proposizione atomica allora l'estensione
  è l'insieme degli stati dove vale la proposizione atomica. Se abbiamo un connettivo
  tra due formule già estese segue la logica dell'operatore (esempio se abbiamo l'and
  in un certo stato è valido sse valgono entrambe le proposizioni).\\
  Passiamo a CTL.\\
  Sia $\alpha\equiv\mathbf{AF}\,\beta$. Si
  definisce la funzione:
  \[f_\alpha:2^Q\to 2^Q\]
  ovvero una funzione che prende un sottoinsieme di stati e lo trasforma in un
  sottoinsieme di stati. Si ha che $\forall H\subseteq Q$:
  \[f_\alpha(H)=[[\beta]]\cup\{q\in Q|\forall(q, q')\in T:q'\in H\}\]
  Si noti che $f_a(\emptyset)=[[\beta]]$.\\
  Si dimostra che $[[\alpha]]$ è il minimo punto fisso di $f_\alpha$.\\
  Ogni volta si aggiungono nuovi stati.\\
  Posso usare lo stesso algoritmo per vedere se $\alpha$ vale in un certo stato,
  osservando se alla fine lo stato che ci interessa è contenuto
  nell'estensione.\\
  Sia ora $\alpha\equiv \mathbf{EG}\,\beta$. Si
  definisce la funzione:
  \[g_\alpha:2^Q\to 2^Q\]
  Si ha che $\forall H\subseteq Q$:
  \[g_\alpha(H)=[[\beta]]\cap\{q\in Q|\exists(q, q')\in T:q'\in H\}\]
  Si noti che $g_\alpha(Q)=[[\beta]]$.\\
  Si dimostra che $[[\alpha]]$ è il massimo punto fisso di $g_\alpha$.\\
  Ogni volta si tolgono stati.\\
  In generale si nota che il ``per ogni'' e l' ``esiste'' compaiono nella
  formula.\\
  Per l'operatore next è sufficiente guardare il passo successivo quindi non
  serve un ragionamento così complesso mentre per l'until si fa un ragionamento
  simile al future, essendo nella pratica una sua forma rafforzata (poi si
  cerca, come per il future, il minimo punto fisso).
\end{definizione} \vspace{5mm} %5mm vertical space
Possiamo quindi trovare un algoritmo per CTL che sarà ricorsivo.
\begin{definizione}
  Definiamo \textbf{$\mu$ calcolo} come un linguaggio logico che permette di
  definire formule ricorsive.  
\end{definizione} \vspace{5mm} %5mm vertical space
Si supponga di avere solo l'operatore temporale next e i
quantificatori. Cerchiamo di esprimere, solo con il next, la proprietà
$\mathbf{EF}\,\alpha$. Si ha quindi una sorta di srotolamento:
\[\mathbf{EF}\,\alpha\equiv \alpha\lor
  \mathbf{EX}\,\alpha\lor\mathbf{EXEX}\,\alpha\lor\cdots\]
che è una formula infinita ma con una struttura ben definita, dal secondo
termine si inizia sempre con $\mathbf{EX}$. Raccogliamo:
\[\mathbf{EF}\,\alpha\equiv \alpha\lor
  \mathbf{EX}(\,\alpha\lor\mathbf{EX}\,\alpha\lor\cdots)\]
ma quindi tra parentesi si ha in pratica la formula completa di
$\mathbf{EF}\,\alpha$ e quindi posso dire che:
\[\mathbf{EF}\,\alpha\equiv\alpha\lor\mathbf{EX}\,(\mathbf{EF}\,\alpha)\]
Fisso quindi una notazione per scrivere questa cosa:
\[\mu Y.(\alpha\lor \mathbf{EX}\, Y)\]
Dove la $\mu$ indica tradizionalmente il minimo punto fisso, Quindi la formula
si legge ``minimo punto fisso della funzione $(\alpha\lor \mathbf{EX}\, Y)$ dove
$Y$ è l'oggetto che cerchiamo di definire''. È quindi una forma compatta di
scrivere la formula infinita.\\
Passo a $\mathbf{AG}\alpha$:
\[\mathbf{AG}\,\alpha\equiv \alpha\land
  \mathbf{AX}\,\alpha\land\mathbf{AXAX}\,\alpha\land\cdots\]
e quindi, raccogliendo:
\[\mathbf{AG}\,\alpha\equiv\alpha\land \mathbf{AX}\,(\mathbf{AG}\alpha)\]
ovvero:
\[\nu Y.(\alpha\land\mathbf{AX}\, Y)\]
Possiamo generalizzare fino ad avere un linguaggio completo, una nuova logica,
detto appunto \textbf{calcolo $\mu$}.
\begin{definizione}
  Dato $AP$ l'insieme delle proposizioni atomiche e siano $\alpha$ e $\beta$ due
  formule. Si ha che la sintassi del linguaggio è:
  \begin{itemize}
    \item $\alpha\lor\beta$ e $\neg \alpha$ sono formule (forse anche le altre
    ottenute con connettivi logici (???))
    \item $\mathbf{AX}\,\alpha$ e $\mathbf{AX}\,\alpha$ sono formule
    \item $\mu Y.f(Y)$ è una formula è una formula, dove $f$ è una formula nella
    quale compare $Y$ (con restrizioni sulle negazioni) 
    \item $\nu Y.f(Y)$ è una formula è una formula, dove $f$ è una formula nella
    quale compare $Y$ (con restrizioni sulle negazioni)
  \end{itemize}
  Si ha quindi un modo molto libero di costruire formule.\\
  La semantica del calcolo $\mu$ è definita sui modelli di Kripke attraverso gli
  operatori di punto fisso, usando idee simili a quelle usate per definire le
  estensioni di formule temporali.
\end{definizione} \vspace{5mm} %5mm vertical space
Si nota che:
\[CTL^*\subset \mbox{calcolo } \mu\]
quindi tutte le formule di $CTL^*$ sono esprimibili nel $\mu$ calcolo che quindi
è più espressivo di tutte le logiche finora considerate (ed esprime anche cose
che le altre non possono). La massima potenza espressiva si paga in complessità
degli algoritmi e con una sorta di ``oscurità'' delle formule, che non sono
facilmente leggibili ed interpretabili.\\
Vediamo qualche dettaglio sulla complessità temporale, dato un modello di
Kripke $M$ e una formula $f$, a parità di algoritmo canonico:
\begin{itemize}
  \item PLTL ha complessità $O(|M|\cdot 2^{|f|})$
  \item CTL ha complessità $O(|M|\cdot |f|)$
\end{itemize}
In realtà la dimensione della formula rende difficile un confronto diretto in
quanto una proprietà può avere una formula breve in LTL e una lunga in CTL (come
abbiamo già visto). Anche il numero di stati, $|M|$, è da non trascurare in
quanto può essere immenso, anche dal punto di vista della complessità
spaziale. Si hanno quindi strategie per la trattazione 
efficiente, tra cui:
\begin{itemize}
  \item rappresentazioni simboliche, tramite diagrammi di traduzione
  binari (Ordered Binary Decision Diagrams, OBDD)
  \item partial order reduction (tramite unfolding), spesso usato per le
  reti di Petri. SI hanno tecniche efficienti dal punto di vista spaziale
  \item traduzione in SAT, usando i SAT solver
\end{itemize}
Quindi, per concludere, per fare model checking una tecnica è ridurre il
problema ad un modello di kripke.\\
Parliamo giusto un secondo di \textbf{fairness}.
\begin{definizione}
  Si dice che un'esecuzione è \textbf{unfair} se un evento rimane sempre
  abilitato da un certo istante in poi ma non scatta mai.\\
\end{definizione} \vspace{5mm} %5mm vertical space
\begin{definizione}
  Si definisce \textbf{fairness debole} se un evento che è abilitato
  prima o poi scatta o viene disabilitato.
\end{definizione} \vspace{5mm} %5mm vertical space
Bisogna quindi limitare la valutazione di una formula alla sua esecuzione
\textbf{fair}, nella realtà è irrealistico pensare che qualcosa non scatti
mai essendo sempre abilitata.
\begin{definizione}
  Si definisce \textbf{fairness forte} se ogni evento che viene abilitato
  infinite volte scatta infinite volte (a lungo termine senza curarsi degli
  aspetti quantitativi). Ovvero, in PLTL, se:
  \[\mathbf{GF}\,(\mbox{evento è abilitato})\to\mathbf{GF}\,(\mbox{evento
      scatta})\] 
\end{definizione} \vspace{5mm} %5mm vertical space
\textbf{Su slide vari esempi per la fairness.}\\
Per il model checking si hanno diversi tool, tra cui:
\begin{itemize}
  \item \textbf{Spin} per PLTL, tramite un linguaggio chiamato Promela
  \item \textbf{NuSMV} per PLTL e CTL
  \item \textbf{mCLR2} per il $\mu$ calcolo
  \item \textbf{TiNA} per PLTL e reti di Petri
\end{itemize}